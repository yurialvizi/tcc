{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c698346b",
   "metadata": {},
   "source": [
    "# MLP\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d69b692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visualization.py already downloaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "LIB_DIR = './lib'\n",
    "SAVED_MODELS_DIR = '../backend/saved_models'\n",
    "SAVED_MODEL_FILE =  '/mlp.pkl'\n",
    "\n",
    "os.makedirs(LIB_DIR, exist_ok=True)\n",
    "sys.path.append(LIB_DIR)\n",
    "os.makedirs(SAVED_MODELS_DIR, exist_ok=True)\n",
    "sys.path.append(SAVED_MODELS_DIR)\n",
    "\n",
    "def install_package(package_name):\n",
    "    try:\n",
    "        importlib.import_module(package_name)\n",
    "        print(f\"{package_name} is already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package_name}\")\n",
    "        %pip install --quiet $package_name --progress-bar on\n",
    "\n",
    "def download_lib(filename, url):\n",
    "    LIB_PATH = os.path.join(LIB_DIR, filename)\n",
    "    if not os.path.exists(LIB_PATH):\n",
    "        print(f\"Downloading {filename}\")\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(url, LIB_PATH)\n",
    "        print(f\"Downloaded {filename} to {LIB_PATH}\")\n",
    "    else:\n",
    "        print(f\"{filename} already downloaded\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import joblib\n",
    "\n",
    "download_lib(\"visualization.py\", \"https://raw.githubusercontent.com/andreaaraldo/machine-learning-for-networks/master/course_library/visualization.py\")\n",
    "\n",
    "import visualization # type: ignore\n",
    "from visualization import plot_conf_mat # type: ignore\n",
    "importlib.reload(visualization)\n",
    "\n",
    "from lib.utils import generate_summary_plot, generate_bar_plot, get_shap_dict, get_metrics_dict, save_to_pickle\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2745d242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "files_path = ''\n",
    "\n",
    "if 'google.colab' in str(get_ipython()): # type: ignore\n",
    "    print('TO DO: Set up Google Colab')\n",
    "    # print('Running in Google Colab')\n",
    "    # from google.colab import drive\n",
    "    # mount_point = '/content/drive'\n",
    "    # drive.mount(mount_point)\n",
    "    # files_path = mount_point + '/MyDrive/Colab Notebooks/'\n",
    "else:\n",
    "    print('Running locally')\n",
    "    files_path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86e8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_df = pd.read_csv(files_path + 'syntetic_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929574bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {\n",
    "    'sex': {\n",
    "        'female': 0,\n",
    "        'male': 1\n",
    "    },\n",
    "    'present_employee_since': {\n",
    "        'unemployed': 0, '<1y': 1, '1-4y': 2, '4-7y': 3, '>=7y': 4\n",
    "    },\n",
    "    'checking_account': {\n",
    "        'no checking account': 0, '< 0 DM': 1, '0 <= ... < 200 DM': 2, '>= 200 DM': 3\n",
    "    },\n",
    "    'savings': {\n",
    "        '0 or unk.': 0, '<100 DM': 1, '100-500 DM': 2, '500-1000 DM': 3, '>1000 DM': 4\n",
    "    },\n",
    "    'job': {\n",
    "        'unemployed/unskilled non-resident': 0,\n",
    "        'unskilled resident': 1,\n",
    "        'qualified': 2,\n",
    "        'highly qualified': 3\n",
    "    }\n",
    "}\n",
    "\n",
    "german_preprocessed_df = german_df.copy()\n",
    "\n",
    "for col, mapping in mappings.items():\n",
    "    german_preprocessed_df[col] = german_preprocessed_df[col].map(mapping).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2493bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "german_dummies_df = pd.get_dummies(german_preprocessed_df, dtype=int, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05f7df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    german_dummies_df.drop(columns=['risk']),\n",
    "    german_dummies_df['risk'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8086265d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beatr\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "pipeline = None\n",
    "if os.path.exists(SAVED_MODELS_DIR + SAVED_MODEL_FILE):\n",
    "    print(f\"Loading saved model ...\")\n",
    "    pipeline = joblib.load(SAVED_MODELS_DIR + SAVED_MODEL_FILE)[\"model\"]\n",
    "else:\n",
    "    pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('mlp', MLPClassifier(\n",
    "                activation='relu',\n",
    "                alpha=0.001,\n",
    "                hidden_layer_sizes=(128, 64, 32),\n",
    "                learning_rate_init=0.01,\n",
    "                max_iter=200,\n",
    "                early_stopping=True,\n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "\n",
    "\n",
    "    pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43343834",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ff4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43dd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "class_names = np.array(['good', 'bad'])\n",
    "plot_conf_mat(y_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b714cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explainable AI\n",
    "scaler = pipeline.named_steps['scaler']\n",
    "mlp_model = pipeline.named_steps['mlp']\n",
    "\n",
    "x_test_xai = scaler.transform(x_test.sample(frac=0.1, random_state=42))\n",
    "\n",
    "explainer = shap.Explainer(mlp_model.predict_proba, x_test_xai, feature_names=x_train.columns)\n",
    "shap_values = explainer(x_test_xai)\n",
    "\n",
    "shap.summary_plot(shap_values[:,:,1], x_test_xai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970dc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.bar(shap_values[:,:,1], max_display=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c10821",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_plot_b64 = generate_summary_plot(shap_values[:, :, 1], x_test_xai)\n",
    "\n",
    "shap_importance_b64 = generate_bar_plot(shap_values[:,:,1], max_display=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb028e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "shap.plots.waterfall(shap_values[sample_index,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61239424",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_data = get_shap_dict(summary_plot_b64, shap_importance_b64, x_test_xai)\n",
    "\n",
    "metrics_data = get_metrics_dict(cm_normalized, class_report)\n",
    "\n",
    "save_to_pickle(pipeline, metrics_data, shap_data, SAVED_MODELS_DIR + SAVED_MODEL_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
